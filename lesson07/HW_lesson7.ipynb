{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_lesson7.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bueuv-h-3sog"
      },
      "source": [
        "Чтобы было больше времени на выполнение курсовой работы, задание выполнить на наборе данных для соревнования:\n",
        "\n",
        "- Тестовая выборка - это выборка для применения модели и загрузки на ЛБ.\n",
        "\n",
        "- Обучить алгоритмы LightGBM и XGBoost, получить OOF прогнозы, оценить корреляцию прогнозов на обучающей выборке. Применить модели на тестовую выборку и оценить корреляцию.\n",
        "\n",
        "- Усреднить прогнозы с помощью арифмитического среднего, геометрического среднего и усреднить ранги, сделать выводы о качестве отдельных моделей и о качестве комбинации.\n",
        "\n",
        "- Обучить CatBoost, получить OOF прогнозы и выполнить задание 1 для трех моделей.\n",
        "\n",
        "Выполнить задание 2 для трех моделей.\n",
        "\n",
        "- (опция) Объединить OOF-прогнозы для трех моделей и обучить алгоритм Логистической регрессии (и любой другой, на ваше усмотрение). Сделать выводы о достигаемом качестве, сравнить достигаемое качество с качеством отдельных моделей и моделей, полученных в п.2 и п.4.\n",
        "\n",
        "- (опция) Обучить алгоритмRandomForest (желательно подтюнить параметры) и добавить к построенным ранее моделям. Выполнить задание 5."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNQdpaCv34gN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}